{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eba1f48-656e-44ac-8969-0e98cd9d87ec",
   "metadata": {},
   "source": [
    "# DWH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaba45f-b982-4273-a94b-aedc17ce5a85",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c5bf56-a39a-4e57-9c0f-37daa2252b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from glob import glob\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23df530d",
   "metadata": {},
   "source": [
    "Eine importierte Stopword Liste aus Github wird verwendet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5b2404-a326-40dc-8d7d-c3eaa5247d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_url = \"https://raw.githubusercontent.com/solariz/german_stopwords/master/german_stopwords_full.txt\"\n",
    "stopwords_list = requests.get(stopwords_url, allow_redirects=True).text.split(\"\\n\")[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5dc714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfade\n",
    "DATA_LAKE_DIR = 'C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\DBU\\\\ads_05\\\\ads_05_studienarbeit\\\\input\\\\data-lake'\n",
    "TEMP_PATH = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\DBU\\\\ads_05\\\\ads_05_studienarbeit\\\\_templates\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74540628-c6e9-4fb7-9fe0-ef64ce7da2b6",
   "metadata": {},
   "source": [
    "## HTML und CSV Parsing Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f30e9",
   "metadata": {},
   "source": [
    "Mit den folgenden Funktionen lassen sich HTML-Dateien auslesen, deren Textinhalte bereinigen und für eine weitere Analyse in einem DataFrame zusammenführen. Dabei werden überflüssige HTML-Tags entfernt, Wörter gefiltert und gezählt sowie zusätzliche Informationen wie das Datum und der Zeitungsname hinzugefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf21b998-f481-4642-8a8d-15e5eb9feade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Liest den Inhalt einer HTML-Datei\n",
    "def read_html_file(file_name, encoding=\"utf-8\"):\n",
    "    with open(file_name, \"r\", encoding=encoding) as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "# Extrahiert und bereinigt Text aus einer HTML-Datei\n",
    "def process_html(text):\n",
    "    text = BeautifulSoup(text, \"html.parser\").text  # Entfernt HTML-Tags\n",
    "    items = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \").lower().split(\" \")  # Zerlegt in Wörter\n",
    "    items = [i for i in items if len(i) > 2 and i not in stopwords_list]  # Filtert Stopwords\n",
    "    return items\n",
    "\n",
    "# Analysiert HTML-Dateien und erstellt ein DataFrame mit Wortzählungen\n",
    "def parse_html(name, date, file_name, encoding):\n",
    "    content = read_html_file(file_name, encoding)  # Lese Dateiinhalt\n",
    "    soup = BeautifulSoup(content, \"html.parser\")  # Parsen des HTML-Inhalts\n",
    "    text = soup.text  # Extrahiert Text\n",
    "    items = process_html(text)  # Verarbeite Text\n",
    "    item_count = pd.Series(items, dtype=\"object\").value_counts()  # Zähle Wörter mit explizitem Datentyp\n",
    "    count = item_count.to_frame()  # Konvertiere in DataFrame\n",
    "    count.columns = [\"count\"]  # Spaltenname setzen\n",
    "    count[\"word\"] = count.index  # Wörter als Index\n",
    "    count[\"date\"] = date  # Datum hinzufügen\n",
    "    count[\"paper\"] = name  # Zeitung hinzufügen\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0722b2d",
   "metadata": {},
   "source": [
    "Die naechste Funktion durchsucht ein angegebenes Verzeichnis nach CSV-Dateien, um darin hinterlegte Informationen (Dateiname, Codierung, Erscheinungsdatum und Zeitungsname) auszulesen. Anschließend werden die zugehörigen HTML-Dateien eingelesen, bereinigt und für eine weiterführende Analyse in einem DataFrame zusammengefasst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d2c2a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv_files_in_directory(directory):\n",
    "    result_list = []  # Liste zum Speichern der Ergebnisse der HTML-Verarbeitung\n",
    "\n",
    "    # Finde alle CSV-Dateien im Verzeichnis\n",
    "    csv_filename_list = glob(os.path.join(directory, \"*.csv\"))  \n",
    "\n",
    "    # Iteriere über jede CSV-Datei\n",
    "    for csv_file in csv_filename_list:  \n",
    "        df = pd.read_csv(csv_file)  # Lese die CSV-Datei in ein DataFrame\n",
    "        df2 = df.dropna()  # Entferne Zeilen mit fehlenden Werten\n",
    "\n",
    "        # Iteriere über jede Zeile im DataFrame\n",
    "        for i, row in df2.iterrows():  \n",
    "            name = row[\"name\"]  # Extrahiere den Namen der Zeitung\n",
    "            file_name = row[\"file_name\"]  # Extrahiere den Dateinamen der HTML-Datei\n",
    "            date = row[\"date\"]  # Extrahiere das Datum\n",
    "            encoding = row[\"encoding\"]  # Extrahiere die Kodierung\n",
    "\n",
    "            # Erstelle den absoluten Pfad zur HTML-Datei\n",
    "            full_path = os.path.join(directory, file_name)  \n",
    "\n",
    "            # Überprüfe, ob die HTML-Datei existiert\n",
    "            if os.path.exists(full_path):  \n",
    "                print(f\"Datei gefunden: {full_path}\")  # Gib eine Meldung aus, wenn die Datei gefunden wurde\n",
    "                count = parse_html(name, date, full_path, encoding)  # Verarbeite die HTML-Datei\n",
    "                result_list.append(count)  # Füge das Ergebnis zur Liste hinzu\n",
    "            else:\n",
    "                print(f\"Datei nicht gefunden: {full_path}\")  # Gib eine Meldung aus, wenn die Datei nicht gefunden wurde\n",
    "\n",
    "    # Füge alle Ergebnisse zu einem DataFrame zusammen\n",
    "    if result_list:  # Überprüfe, ob die Ergebnisliste nicht leer ist\n",
    "        final_result_df = pd.concat(result_list, ignore_index=True)  # Kombiniere die DataFrames\n",
    "        return final_result_df  # Gib den kombinierten DataFrame zurück\n",
    "    else:\n",
    "        return pd.DataFrame()  # Gib einen leeren DataFrame zurück, wenn keine Ergebnisse vorhanden sind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f780e7cc",
   "metadata": {},
   "source": [
    "Funktion um ein Dataframe nach Schlüsselwörtern zu filtern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d512074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtert ein DataFrame basierend auf Schlüsselwörtern\n",
    "def filter_words(df, column, keywords):\n",
    "    def extract_keyword(text):\n",
    "        for keyword in keywords:  # Prüfe jedes Schlüsselwort\n",
    "            if keyword in text:\n",
    "                return keyword  # Rückgabe des ersten Treffers\n",
    "        return None  \n",
    "\n",
    "    df[column] = df[column].apply(extract_keyword)  # Anwenden auf die Spalte\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba6ff8",
   "metadata": {},
   "source": [
    "## HTML-Dateien Lesen und Verarbeiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413d75b",
   "metadata": {},
   "source": [
    "Dieser Abschnitt verarbeitet die aggregierten Wortzählungen aus den CSV-Dateien, filtert sie nach den definierten Parteien und bereitet das Ergebnis für weitere Analysen vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc04b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verarbeite Dateien und speichere das Ergebnis\n",
    "result = parse_csv_files_in_directory('C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\DBU\\\\ads_05\\\\ads_05_studienarbeit\\\\input\\\\data-lake')\n",
    "print(result.head())  # Zeige die ersten Zeilen des DataFrames an"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a73ff1",
   "metadata": {},
   "source": [
    "Eine Kopie erstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea7549",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = result.copy()  # Kopiere das DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8f48d",
   "metadata": {},
   "source": [
    "Nach den Parteien filtern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17faeccc-c3cb-47f5-967b-62e14233e50a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count  word        date paper\n",
      "0     82  None  2021-04-01    sz\n",
      "1     44  None  2021-04-01    sz\n",
      "2     40  None  2021-04-01    sz\n",
      "3     22  None  2021-04-01    sz\n",
      "4     17  None  2021-04-01    sz\n"
     ]
    }
   ],
   "source": [
    "# Liste der zu filternden Parteien\n",
    "keywords = ['spd', 'cdu', 'afd', 'fdp', 'grünen', 'linke', 'bsw']\n",
    "\n",
    "# Wende die Filterung auf 'result' an\n",
    "party_df = filter_words(copy, 'word', keywords)\n",
    "\n",
    "# Zeige die ersten Zeilen des gefilterten DataFrames an\n",
    "print(party_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09abe66c-8f72-4f56-8a9e-d752d7976a07",
   "metadata": {},
   "source": [
    "## Politbarometer-Daten einlesen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f4211",
   "metadata": {},
   "source": [
    "Dieser Codeabschnitt lädt die Wahlergebnisse aus einer CSV-Datei, benennt die Spalten um und formatiert das Datum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47737ce8-d3ca-440a-a7ca-1caa16ae9667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  CDU  SPD  Grüne   FDP  Linke  AfD  BSW\n",
      "0 1991-02-15   43   35      7  10.0    2.0  NaN  NaN\n",
      "1 1991-03-15   42   37      7  10.0    2.0  NaN  NaN\n",
      "2 1991-04-26   41   38      7  10.0    2.0  NaN  NaN\n",
      "3 1991-05-24   41   39      6  10.0    2.0  NaN  NaN\n",
      "4 1991-06-14   40   40      6   9.0    2.0  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "# Vollständigen Pfad zur Excel-Datei angeben\n",
    "file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\DBU\\\\ads_05\\\\ads_05_studienarbeit\\\\input\\\\politbarometer.xlsx\"\n",
    "\n",
    "# Lese die Excel-Datei ein und wähle das relevante Arbeitsblatt\n",
    "wahlen_df = pd.read_excel(file_path, sheet_name='Tabelle1', usecols=[0, 1, 2, 3, 4, 5, 6, 7], parse_dates=[0])\n",
    "\n",
    "# Benenne die Spalten für bessere Lesbarkeit um\n",
    "wahlen_df.columns = ['date', 'CDU', 'SPD', 'Grüne', 'FDP', 'Linke', 'AfD', 'BSW']\n",
    "\n",
    "# Konvertiere die 'date'-Spalte in das Datetime-Format\n",
    "wahlen_df['date'] = pd.to_datetime(wahlen_df['date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# Entferne Zeilen mit ungültigen Datumswerten (falls vorhanden)\n",
    "wahlen_df = wahlen_df.dropna(subset=['date'])\n",
    "\n",
    "# Zeige die ersten fünf Zeilen des DataFrames an\n",
    "print(wahlen_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5123b123-6478-4935-b7e8-fe19380efe11",
   "metadata": {},
   "source": [
    "## Als pickle speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc09b76-6810-420e-9968-ef5f09bf8c36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wahlen_df.to_pickle(os.path.join(TEMP_PATH, \"politbarometer.pickle\"))\n",
    "party_df.to_pickle(os.path.join(TEMP_PATH, \"parteien.pickle\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
